---
title: "Photosynthesis and respiration rate calculations"
output: html_document
---



Trying Danielle's code 
```{r}
rm(list=ls()) #clears workspace 

## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools') 
library('devtools')
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented') 
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix') 
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra') 
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR') 
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate') 
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron') 
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr') 
if ("tidyverse" %in% rownames(installed.packages()) == 'FALSE') install.packages('tidyverse') 


#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
library(patchwork)
library("segmented")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library(dplyr)
library('tidyverse')


##### PHOTOSYNTHESIS AND RESPIRATION #####
# get file path
path.p <- "../data/1_pi_curves/PI_curve_resp/" #the location of all your respirometry files 

# bring in oxygen files 
file.names<-basename(list.files(path = path.p, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
#basename above removes the subdirectory name from the file
#add file names that include the subdirectory name (note, these are the same for this example, but I often have lots of subfolders for different Runs)
file.names.full<-list.files(path = path.p, pattern = "csv$", recursive = TRUE) #list all csv file names in the folder and subfolders

#generate an dataframe with specific column names
Photo.R <- data.frame(matrix(NA, nrow=length(file.names), ncol=4))
colnames(Photo.R) <- c("plug_id","Intercept", "umol.L.sec","Temp.C") # name the columns

#Load Sample Info
Sample.Info <- read.csv(file=paste0(path.p,"/../TEST_resp_data.csv"), header=T) #read sample.info data
Sample.Info <- Sample.Info[,-c(7:9)]

# load surface area data
SA <- read.csv(file=paste0(path.p,"/../TEST_sample_info_PI.csv"), header=T) #read sample.info data
# add 620 ml to the NAs in volume (the blanks)
#Calculat the volume of water
as.numeric(SA$volume)

#Sample.Info$Volume[which(is.na(Sample.Info$Volume))]<-650
# add 0's for the "not blanks"
View(SA)

# joint the sample info and surface area and volume measurements
Sample.Info<-left_join(Sample.Info, SA)
View(Sample.Info)

PR<-c('Photo','Resp')


 # for every file in list calculate O2 uptake or release rate and add the data to the Photo.R dataframe
for(i in 1:length(file.names.full)) { # for every file in list calculate O2 uptake or release rate and add the data to the Photo.R dataframe
  
  #find the lines in sample info that have the same file name that is being brought it
  FRow<-which(Sample.Info$plug_id==strsplit(file.names[i],'.csv'))
  
  # read in the O2 data one by one
  Photo.Data1 <-read.csv(file.path(path.p,file.names.full[i]), skip = 1, header=T) # skips the first line
  colnames(Photo.Data1) <- c("Date", "Time", "ID", "Delta_T",	"Device",	"Channel", "Sensor", "Calibration", "User", "Value",	"OxygenUnit",	"Temp",	"TemperatureUnit", 	"Pressure",	"PressureUnit",	"Mode",	"Salinity", "Error")
  Photo.Data1  <- Photo.Data1[,c("Time","Value","Temp")] #subset columns of interest
  Photo.Data1$Time <- as.POSIXct(Photo.Data1$Time,format="%H:%M:%S", tz = "") #convert time from character to time
  Photo.Data1 <- na.omit(Photo.Data1)

  
  # clean up some of the data
    n<-dim(Photo.Data1)[1] # length of full data
    #Photo.Data1 <-Photo.Data1[(n-120):(n-3),] #start at data point ~2 minute in to avoid excess noise from start of run and remove last 3 lines containing text
    n<-dim(Photo.Data1)[1] #list length of trimmed data
    Photo.Data1$sec <- (1:n) #set seconds by one from start to finish of run in a new column
  
    
    #Save plot prior to and after data thinning to make sure thinning is not too extreme
    rename <- sub(".csv","", file.names[i]) # remove all the extra stuff in the file name
     
    pdf(paste0("../Output/",rename,"thinning.pdf")) # open the graphics device

    par(omi=rep(0.3, 4)) #set size of the outer margins in inches
    par(mfrow=c(1,2)) #set number of rows and columns in multi plot graphic
    plot(Value ~ sec, data=Photo.Data1 , xlab='Time (seconds)', ylab=expression(paste(' O'[2],' (',mu,'mol/L)')), type='n', axes=FALSE) #plot (empty plot to fill) data as a function of time
    usr  <-  par('usr') # extract the size of the figure margins
    rect(usr[1], usr[3], usr[2], usr[4], col='grey90', border=NA) # put a grey background on the plot
    whiteGrid() # make a grid
    box() # add a box around the plot
    points(Photo.Data1 $Value ~ Photo.Data1 $sec, pch=16, col=transparentColor('dodgerblue2', 0.6), cex=1.1)
    axis(1) # add the x axis
    axis(2, las=1) # add the y-axis
    
    # This the data to make the code run faster
    Photo.Data.orig<-Photo.Data1#save original unthinned data
    Photo.Data1 <-  thinData(Photo.Data1 ,by=20)$newData1 #thin data by every 20 points for all the O2 values
    Photo.Data1$sec <- as.numeric(rownames(Photo.Data1 )) #maintain numeric values for time
    Photo.Data1$Temp<-NA # add a new column to fill with the thinned data
    Photo.Data1$Temp <-  thinData(Photo.Data.orig,xy = c(1,3),by=20)$newData1[,2] #thin data by every 20 points for the temp values
   
    # plot the thinned data
    plot(Value ~ sec, data=Photo.Data1 , xlab='Time (seconds)', type='n', axes=FALSE) #plot thinned data
    usr  <-  par('usr')
    rect(usr[1], usr[3], usr[2], usr[4], col='grey90', border=NA)
    whiteGrid()
    box()
    points(Photo.Data1 $Value ~ Photo.Data1 $sec, pch=16, col=transparentColor('dodgerblue2', 0.6), cex=1.1)
    axis(1)
    axis(2, las=1)
    ##Olito et al. 2017: It is running a bootstrapping technique and calculating the rate based on density
    #option to add multiple outputs method= c("z", "eq", "pc")
    Regs  <-  rankLocReg(xall=Photo.Data1$sec, yall=Photo.Data1$Value, alpha=0.5, method="pc", verbose=TRUE)  
   
    # add the regression data
    plot(Regs)
    dev.off()
    
    # fill in all the O2 consumption and rate data
    Photo.R[i,2:3] <- Regs$allRegs[1,c(4,5)] #inserts slope and intercept in the dataframe
    Photo.R[i,1] <- rename #stores the file name in the Date column
    Photo.R[i,4] <- mean(Photo.Data1$Temp, na.rm=T)  #stores the Temperature in the Temp.C column
    Photo.R[i,5] <- PR[j] #stores whether it is photosynthesis or respiration
 
    
    # rewrite the file everytime... I know this is slow, but it will save the data that is already run
    done
}

```

Running the for loop just goes forever until I manually stop the code. When I stop it, I get this error: Error in base::try(metadata, TRUE) : object 'metadata' not found
Not sure what its referring too, continue looking















```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

## install packages if you dont already have them in your library
if (!require("devtools")) install.packages("devtools")
if (!require("furrr")) install.packages("furrr")
if (!require("future")) install.packages("future")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("lubridate")) install.packages("lubridate")
if (!require("cowplot")) install.packages("cowplot")
if (!require("LoLinR")) install_github('colin-olito/LoLinR') 

## load libraries
library(devtools)
library(LoLinR)
library(tidyverse)
library(lubridate)
library(cowplot)

## libraries for parallel processing
library(future)
library(furrr)
```

## Import data
```{r}
path.p <- "../data/1_pi_curves/" #the location of all your respirometry files 

# List data files
file.names <- list.files(path = path.p, pattern = "csv$")  # list all csv file names in the folder
file.names <- file.names[!grepl("metadata", file.names)]   # omit metadata from files to be read in as data

# Load PI curve sample metadata (i.e., which corals were in which runs)
sample.info <- read_csv(file = "../data/1_pi_curves/1_pi_curves_sample_metadata.csv")

# Load PI curve run metadata (i.e., light levels and interval times for each run)
run.info <- read_csv(file = "../data/1_pi_curves/1_pi_curves_run_metadata.csv")
summary(run.info$Stop.time)

# Join all coral and run metadata
metadata <- full_join(sample.info, run.info) %>%
  mutate(Date = as_date(as.character(Date), format = "%Y%m%d", tz = "PF"))
metadata <- metadata[-c(81:152), ]

# Select only certain columnns
metadata <- metadata %>%
  select(Date, plug_id, Run, Chamber.Vol.L, Surface.Area.cm2, Light_Value, Start.time, Stop.time) 
    
# Read in all data files
df <- tibble(file.name = file.names) %>%
  mutate(plug_id = gsub("_.*", "", file.name),                              # Get colony_id from filename
          info = map(plug_id, ~filter(metadata, plug_id == .)),           # Get associated sample info
         data0 = map(file.name, ~read_csv(file.path(path.p, .), skip = 0)))   # Get associated O2 data

# Select only Time, Value, and Temp columns from O2 data
df <- df %>%
  mutate(data0 = map(data0, ~select(., Time, Value, Temp)))  
df$data0[[8]]
df$info[[1]]
```

## Use the time breaks in the sample info to link O2 data with light levels
```{r, warning = FALSE}
df <- df %>%
  mutate(intervals = map2(data0, info, function(.x, .y) {
    split(.x, f = cut(as.numeric(.x$Time), breaks = as.numeric(c(.y$Start.time, last(.y$Stop.time))),
                      labels = as.character(.y$Light_Value)))})) %>%
  mutate(data = map(intervals, ~ unnest(tibble(.), .id = "Light_Value")))

## 'data' now contains the O2 data with the corresponding light level as another column
## Example of what 'data' for each sample looks like:
#df$data[[1]]




```

### Thin data
```{r, fig.height = 8, fig.width = 8}
# Set thinning parameter
thin_par <- 20

# Thin data for all samples
df <- df %>%
  mutate(thin_data = map(data, ~ slice(., seq(1, nrow(.), thin_par))))

# Create plots for full dataset and thinned data
df <- df %>%
  mutate(data_plot = map2(data, colony_id, ~ ggplot(.x, aes(x = Time, y = Value)) + 
                            facet_wrap(~ as.numeric(Light_Value), scales = "free") +
                            geom_point() +
                            labs(title = .y)),
    thin_data_plot = map2(thin_data, colony_id, ~ ggplot(.x, aes(x = Time, y = Value)) + 
                            facet_wrap(~ as.numeric(Light_Value), scales = "free") +
                            geom_point() +
                            labs(title = .y)))

# Example of plots
cowplot::plot_grid(df$data_plot[[1]], df$thin_data_plot[[1]], nrow = 2,
                   labels = c("Example plot: all data", "Example plot: thinned data"))
```

#### The full or thinned data plot for any sample can be accessed like this:
```
df %>%
  filter(colony_id == "ACR-185") %>%
  pull(thin_data_plot)
```

# Fit regressions to each interval for each sample
```{r}
# Define function for fitting LoLinR regressions to be applied to all intervals for all samples
fit_reg <- function(df) {
  rankLocReg(xall = as.numeric(df$Time), yall = df$Value, 
             alpha = 0.2, method = "pc", verbose = FALSE)
}

# Setup for parallel processing
future::plan(multiprocess)

# Map LoLinR function onto all intervals of each sample's thinned dataset
df <- df %>%
  mutate(regs = furrr::future_map(thin_data, function(.) {       # future_map executes function in parallel
    group_by(., Light_Value) %>%
    do(rankLcRg = fit_reg(.))
  }))

## Now 'regs' contains the fitted local regressions for each interval of each sample's thinned dataset

# Define function to pull out and plot regression diagnostics
plot_rankLcRg <- function(colony_id, interval_number) {
  df %>%
    filter(colony_id == colony_id) %>%
    pluck("regs", 1, "rankLcRg", interval_number) %>%
    plot()
}
```

#### The diagnostics for any regression can be plotted like this, specifying a colony_id and the number of the light curve interval:
```
plot_rankLcRg("AST-1337", 1) #this does not seem to be working
```

### Extract slope of best regression for each interval for each sample
```{r}
df.out <- df %>% 
  unnest(regs) %>%
  mutate(micromol.L.s = map_dbl(rankLcRg, ~ pluck(., "allRegs", "b1", 1)))
```

# Adjust by chamber volume and normalize to surface area
```{r}
### Merge rates with sample info
pr <- left_join(
  select(df.out, colony_id, Light_Value, micromol.L.s),
  distinct(metadata, colony_id, Run, Chamber.Vol.L, Surface.Area.cm2)
)

### Correct for chamber volume and blanks
pr <- pr %>%
  mutate(micromol.s = micromol.L.s * Chamber.Vol.L)

# Get blank values -- average for each run and light value in case multiple blanks
blanks <- pr %>%
  filter(grepl("BK", colony_id)) %>%
  group_by(Run, Light_Value) %>%
  summarise(micromol.s.blank = mean(micromol.s))

# Join blank values with rest of data and subtract values from samples for same run and light value
pr <- left_join(pr, blanks) %>%
  mutate(micromol.s.adj = micromol.s - micromol.s.blank) %>%
  # After correcting for blank values, remove blanks from data
  filter(!grepl("BK", colony_id))


# Normalize rates by surface area
pr <- pr %>%
  mutate(micromol.cm2.s = micromol.s.adj / Surface.Area.cm2,
         micromol.cm2.h = micromol.cm2.s * 3600)
```

# Plot rates vs. irradiance for each sample
```{r, fig.height=2, fig.width = 8}
ggplot(pr, aes(x = as.numeric(Light_Value), y = micromol.cm2.h)) +
  geom_point() +
  facet_wrap(~colony_id, scale = "free_y", ncol = 9)
```

# Write to output file
```{r}
# Select variables to write to file
pr.out <- pr %>% select(colony_id, Light_Value, Run, micromol.cm2.s, micromol.cm2.h)

# Write to output file
write.csv(pr.out, "output/1_pi_curve_rates.csv")
```

